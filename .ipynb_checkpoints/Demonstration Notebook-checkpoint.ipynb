{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/RobMcH/CYK-Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ikergarcia1996/Basic-CYK-Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/denizzagli/Context-Free-Grammars-CFGs/blob/master/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Basic but non working great CYK Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rob_CYK_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S', 'NP', 'VP'], ['S', 'S0', 'Q'], ['S0', 'NP', 'VP'], ['S', 'VP', 'Q'], ['NP', 'NP', 'NP'], ['NP', 'NP', 'P'], ['PP', 'P', 'NP'], ['VP', 'V', 'NP'], ['VP', 'PP', 'NP'], ['NP', 'işçiler'], ['NP', 'çatal'], ['NP', 'teleskop'], ['NP', 'hamburgeri'], ['NP', 'dün'], ['NP', 'arkadaşıma'], ['NP', 'hediye'], ['NP', 'romanları'], ['NP', 'ağır'], ['NP', 'ben'], ['NP', 'sen'], ['NP', 'biz'], ['VP', 'yediler'], ['VP', 'aldım'], ['VP', 'okuyorum'], ['VP', 'yürüyoruz'], ['P', 'ile'], ['P', 've'], ['Q', 'mi']]\n"
     ]
    }
   ],
   "source": [
    "CYK = Parser('grammar_for_rob.txt')\n",
    "CYK2 = Parser('Grammar/turkish_grammar_for_rob.txt')\n",
    "CYK3 = Parser('Grammar/turkish_grammar_with_morphology.txt')\n",
    "\n",
    "print(CYK2.grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given sentence is contained in the language produced by the given grammar!\n",
      "\n",
      "Possible parse(s):\n",
      "[S [NP 'astronomers'] [VP [V 'saw'] [NP [NP 'stars'] [PP [P 'with'] [NP 'telescope']]]]]\n",
      "[S [NP 'astronomers'] [VP [VP [V 'saw'] [NP 'stars']] [PP [P 'with'] [NP 'telescope']]]]\n",
      "The given sentence is contained in the language produced by the given grammar!\n",
      "\n",
      "Possible parse(s):\n",
      "[S [S0 [NP [NP 'işçiler'] [NP [NP 'hamburgeri'] [NP [NP 'çatal'] [P 'ile']]]] [VP 'yediler']] [Q 'mi']]\n",
      "[S [S0 [NP [NP 'işçiler'] [NP [NP [NP 'hamburgeri'] [NP 'çatal']] [P 'ile']]] [VP 'yediler']] [Q 'mi']]\n",
      "[S [S0 [NP [NP [NP 'işçiler'] [NP 'hamburgeri']] [NP [NP 'çatal'] [P 'ile']]] [VP 'yediler']] [Q 'mi']]\n",
      "[S [S0 [NP [NP [NP 'işçiler'] [NP [NP 'hamburgeri'] [NP 'çatal']]] [P 'ile']] [VP 'yediler']] [Q 'mi']]\n",
      "[S [S0 [NP [NP [NP [NP 'işçiler'] [NP 'hamburgeri']] [NP 'çatal']] [P 'ile']] [VP 'yediler']] [Q 'mi']]\n",
      "The given sentence is contained in the language produced by the given grammar!\n",
      "\n",
      "Possible parse(s):\n",
      "[S [NP [NP 'dün'] [NP [NP 'arkadaşıma'] [NP 'hediye']]] [VP 'aldım']]\n",
      "[S [NP [NP [NP 'dün'] [NP 'arkadaşıma']] [NP 'hediye']] [VP 'aldım']]\n",
      "The given sentence is contained in the language produced by the given grammar!\n",
      "\n",
      "Possible parse(s):\n",
      "[S [NP [NP 'ben'] [NP 'romanları']] [VP 'okuyorum']]\n",
      "The given sentence is contained in the language produced by the given grammar!\n",
      "\n",
      "Possible parse(s):\n",
      "[S [NP [NP 'ağır'] [NP 'romanları']] [VP 'yediler']]\n",
      "The given sentence is contained in the language produced by the given grammar!\n",
      "\n",
      "Possible parse(s):\n",
      "[S [NP 'biz'] [VP 'yürüyoruz']]\n"
     ]
    }
   ],
   "source": [
    "CYK.parse('astronomers saw stars with telescope')\n",
    "CYK.print_tree()\n",
    "\n",
    "CYK2.parse('işçiler hamburgeri çatal ile yediler mi')\n",
    "CYK2.print_tree()\n",
    "\n",
    "CYK2.parse('dün arkadaşıma hediye aldım')\n",
    "CYK2.print_tree()\n",
    "\n",
    "CYK2.parse('ben romanları okuyorum')\n",
    "CYK2.print_tree()\n",
    "\n",
    "CYK2.parse('ağır romanları yediler')\n",
    "CYK2.print_tree()\n",
    "\n",
    "CYK2.parse('biz yürüyoruz')\n",
    "CYK2.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So called Basic CYK Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from garcia_CYK_Parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grammar file readed succesfully. Rules readed:\n",
      "S --> NP VP\n",
      "PP --> P NP\n",
      "VP --> V NP\n",
      "VP --> VP PP\n",
      "NP --> NP PP\n",
      "NP --> astronomers\n",
      "NP --> ears\n",
      "NP --> saw\n",
      "V --> saw\n",
      "NP --> telescope\n",
      "NP --> stars\n",
      "P --> with\n",
      "\n",
      "\n",
      "Grammar file readed succesfully. Rules readed:\n",
      "S --> NP VP\n",
      "S --> NP VP Q\n",
      "S --> VP Q\n",
      "NP --> NP NP\n",
      "NP --> NP P\n",
      "PP --> P NP\n",
      "VP --> V NP\n",
      "VP --> PP NP\n",
      "NP --> işçiler\n",
      "NP --> çatal\n",
      "NP --> teleskop\n",
      "NP --> hamburgeri\n",
      "NP --> dün\n",
      "NP --> arkadaşıma\n",
      "NP --> hediye\n",
      "NP --> romanları\n",
      "NP --> ağır\n",
      "NP --> ben\n",
      "NP --> sen\n",
      "NP --> biz\n",
      "VP --> yediler\n",
      "VP --> aldım\n",
      "VP --> okuyorum\n",
      "VP --> yürüyoruz\n",
      "P --> ile\n",
      "P --> ve\n",
      "Q --> mi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = Grammar('grammar.txt')\n",
    "g2 = Grammar('Grammar/turkish_grammar_for_rob.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied Rule: VP[2,2] --> V[1,2] NP[1,3]\n",
      "Applied Rule: PP[2,4] --> P[1,4] NP[1,5]\n",
      "Applied Rule: S[3,1] --> NP[1,1] VP[2,2]\n",
      "Applied Rule: NP[3,3] --> NP[1,3] PP[2,4]\n",
      "Applied Rule: VP[4,2] --> V[1,2] NP[3,3]\n",
      "Applied Rule: VP[4,2] --> VP[2,2] PP[2,4]\n",
      "Applied Rule: S[5,1] --> NP[1,1] VP[4,2]\n",
      "Applied Rule: S[5,1] --> NP[1,1] VP[4,2]\n",
      "----------------------------------------\n",
      "The sentence IS accepted in the language\n",
      "Number of possible trees: 2\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The word geldim is not in the grammar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0ea0c68060c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astronomers saw stars with telescope'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ben geldim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/busra/8EE89E22E89E089B/School/CMPE561/Assignment2/Ours/CMPE-561-HW2/garcia_CYK_Parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The word \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is not in the grammar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The word geldim is not in the grammar"
     ]
    }
   ],
   "source": [
    "g.parse('astronomers saw stars with telescope')\n",
    "g2.parse('ben geldim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.print_parse_table()\n",
    "g2.print_parse_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.grammar_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammar Parsar Test and Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global dictionary used for storing the rules.\n",
    "RULE_DICT = {}\n",
    "\n",
    "\n",
    "def read_grammar(grammar_file):\n",
    "    \"\"\"\n",
    "    Reads in the given grammar file and splits it into separate lists for each rule.\n",
    "    :param grammar_file: the grammar file to read in.\n",
    "    :return: the list of rules.\n",
    "    \"\"\"\n",
    "    with open(grammar_file, encoding = 'utf-8') as cfg:\n",
    "        lines = cfg.readlines()\n",
    "    return [x.replace(\"->\", \"\").split() for x in lines]\n",
    "\n",
    "\n",
    "def add_rule(rule):\n",
    "    \"\"\"\n",
    "    Adds a rule to the dictionary of lists of rules.\n",
    "    :param rule: the rule to add to the dict.\n",
    "    \"\"\"\n",
    "    global RULE_DICT\n",
    "\n",
    "    if rule[0] not in RULE_DICT:\n",
    "        RULE_DICT[rule[0]] = []\n",
    "    RULE_DICT[rule[0]].append(rule[1:])\n",
    "\n",
    "\n",
    "def convert_grammar(grammar):\n",
    "    \"\"\"\n",
    "        Converts a context-free grammar in the form of\n",
    "\n",
    "        S -> NP VP\n",
    "        NP -> Det ADV N\n",
    "\n",
    "        and so on into a chomsky normal form of that grammar. After the conversion rules have either\n",
    "        exactly one terminal symbol or exactly two non terminal symbols on its right hand side.\n",
    "\n",
    "        Therefore some new non terminal symbols might be created. These non terminal symbols are\n",
    "        named like the symbol they replaced with an appended index.\n",
    "    :param grammar: the CFG.\n",
    "    :return: the given grammar converted into CNF.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove all the productions of the type A -> X B C or A -> B a.\n",
    "    global RULE_DICT\n",
    "    unit_productions, result = [], []\n",
    "    res_append = result.append\n",
    "    index = 0\n",
    "\n",
    "    for rule in grammar:\n",
    "        new_rules = []\n",
    "        if len(rule) == 2 and rule[1][0] != \"'\":\n",
    "            # Rule is in form A -> X, so back it up for later and continue with the next rule.\n",
    "            unit_productions.append(rule)\n",
    "            add_rule(rule)\n",
    "            continue\n",
    "        elif len(rule) > 2:\n",
    "            # Rule is in form A -> X B C [...] or A -> X a.\n",
    "            terminals = [(item, i) for i, item in enumerate(rule) if item[0] == \"'\"]\n",
    "            if terminals:\n",
    "                for item in terminals:\n",
    "                    # Create a new non terminal symbol and replace the terminal symbol with it.\n",
    "                    # The non terminal symbol derives the replaced terminal symbol.\n",
    "                    rule[item[1]] = f\"{rule[0]}{str(index)}\"\n",
    "                    new_rules += [f\"{rule[0]}{str(index)}\", item[0]]\n",
    "                index += 1\n",
    "            while len(rule) > 3:\n",
    "                new_rules.append([f\"{rule[0]}{str(index)}\", rule[1], rule[2]])\n",
    "                rule = [rule[0]] + [f\"{rule[0]}{str(index)}\"] + rule[3:]\n",
    "                index += 1\n",
    "        # Adds the modified or unmodified (in case of A -> x i.e.) rules.\n",
    "        add_rule(rule)\n",
    "        res_append(rule)\n",
    "        if new_rules:\n",
    "            result.extend(new_rules)\n",
    "    # Handle the unit productions (A -> X)\n",
    "    while unit_productions:\n",
    "        rule = unit_productions.pop()\n",
    "        if rule[1] in RULE_DICT:\n",
    "            for item in RULE_DICT[rule[1]]:\n",
    "                new_rule = [rule[0]] + item\n",
    "                if len(new_rule) > 2 or new_rule[1][0] == \"'\":\n",
    "                    res_append(new_rule)\n",
    "                else:\n",
    "                    unit_productions.append(new_rule)\n",
    "                add_rule(new_rule)\n",
    "    return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
